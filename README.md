# LLM-Finetuning

The repository contains **Part 3** of an LLM Pipeline for Design Exploration.

This project covers collecting, cleaning and formatting a text dataset to be used for LLM finetuning - checkout [Part 1](https://github.com/jomi13/LLM-Knowledge-Pool-RAG) and [Part 2](https://github.com/jomi13/LLM-Conversational-Agents) first.

## Setup
1. Clone this repo into the same parent folder as the previous repos.
```bash
git clone https://github.com/jomi13/LLM-Finetuning
```
2. Your folder structure should now look like this:
```bash
>parent folder<
    -LLM-Knowlege-Pool-RAG
    -LLM-Conversational-Agents
    -LLM-Finetuning
    -myenv
```
3. In Visual Studio Code, donÂ´t forget to choose python to use `myenv`. Take a look at Part 2 for more details.

## Running

--This project contains a few scripts that can help you build a custom dataset for finetune:
- `01_scrape` is an example of a scraper that collects text corpus from webpages.
- `02_cleanup` merges and cleans the text collected previously. 
- `03_summarize` processes the text before its used to get a paired response for finetune.
- `04_format` uses an LLM to create synthetic pairs of input-output. We structure our dataset for finetuning with the Alpaca format.

--If you want to use a corpus of text that you already collected after parsing a PDF (check Part 2 to learn how), you can disregard scripts `01 / 02` or even `03` if you donÂ´t need any post-processing step (summarization, formatting, classification, etc).

--Once your dataset is ready, head over to [this Collab Notebook](https://colab.research.google.com/drive/1gIzuNutwRh08iuRhQmNAti2wDB2X4fmJ?usp=sharing) to finetune a base model of choice. We are using an edited version of a notebook by the [unsloth team](https://github.com/unslothai/unsloth). Props to them!

**Use this repo as a starting point to understand how to format Finetune Datasets, and then go build your own. Unsloth gives you plenty of options when choosing a base model. Think about which would work best for your usecase.**
